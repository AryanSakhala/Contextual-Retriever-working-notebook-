**Contextual Retrieval using VLLM Notebook using llamaIndex**

This notebook provides a comprehensive guide for implementing **Contextual Retrieval** using **VLLM**. To get started, follow these essential steps:

### Setting up VLLM

* Replace `<YOUR_API_URI>` with the actual address where **VLLM** is hosted.
* Ensure the correct **model** and **max_tokens** are set for your specific use case.
* Adjust or set the **`prompt_template`** to align with your project's requirements.

### Milvus Vector DB Setup

* Set up **Milvus Vector DB** and verify it's running correctly.

**Best of Luck with Your Project!**



g&#8203;o&#8203;o&#8203;d&#8203; &#8203;m&#8203;o&#8203;r&#8203;n&#8203;i&#8203;n&#8203;g
